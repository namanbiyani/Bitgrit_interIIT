{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shobhit/Documents/interiit/env/lib/python3.7/site-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "train=pd.read_csv(r'train.csv')\n",
    "test=pd.read_csv(r'test.csv')\n",
    "\n",
    "x_train = train\n",
    "# x_train['Date'] = pd.to_datetime(x_train['Date'], errors='coerce')\n",
    "# x_train['Season'] = x_train['Date'].dt.month\n",
    "# x_train['Season']=x_train['Season'].replace([4,5,6,7,8,9],1)\n",
    "# x_train['Season']=x_train['Season'].replace([1,2,3,10,11,12],0)\n",
    "# x_train['Weekend'] = x_train['Date'].dt.dayofweek\n",
    "# x_train['Weekend']=x_train['Weekend'].replace([0,1,2,3,4,5,6],[0,0,0,0,1,1,0])\n",
    "# x_train.drop(['Date'],inplace=True,axis=1)\n",
    "\n",
    "x_train_A = x_train[x_train['Procedure']=='A']\n",
    "x_train_B = x_train[x_train['Procedure']=='B']\n",
    "x_train_C = x_train[x_train['Procedure']=='C']\n",
    "\n",
    "# P_1 = [1 if x is 'A' else 0 for x in x_train['Procedure']]\n",
    "# P_2 = [1 if x is 'B' else 0 for x in x_train['Procedure']]\n",
    "# P_3 = [1 if x is 'C' else 0 for x in x_train['Procedure']]\n",
    "# x_train['P_1'] = P_1\n",
    "# x_train['P_2'] = P_2\n",
    "# x_train['P_3'] = P_3\n",
    "y_train_A = x_train_A['n_Procedure']\n",
    "y_train_B = x_train_B['n_Procedure']\n",
    "y_train_C = x_train_B['n_Procedure']\n",
    "x_train_A.drop(['Procedure','Date','n_Procedure'],inplace=True,axis=1)\n",
    "x_train_B.drop(['Procedure','Date','n_Procedure'],inplace=True,axis=1)\n",
    "x_train_C.drop(['Procedure','Date','n_Procedure'],inplace=True,axis=1)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# x_train_A=scaler.fit_transform(x_train_A)\n",
    "\n",
    "# x_train_B=scaler.fit_transform(x_train_B)\n",
    "# x_train_C=scaler.fit_transform(x_train_C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_a = []\n",
    "y_a = []\n",
    "x_b = []\n",
    "y_b = []\n",
    "x_c = []\n",
    "y_c = []\n",
    "for i in range(len(x_train)):\n",
    "    if(x_train['Procedure'][i] == 'A'):\n",
    "        x_a.append([x_train['Temperature'][i],x_train['EventTarget'][i]])\n",
    "        y_a.append(x_train['n_Procedure'][i])\n",
    "    elif(x_train['Procedure'][i] == 'B'):\n",
    "        x_b.append([x_train['Temperature'][i],x_train['EventTarget'][i]])\n",
    "        y_b.append(x_train['n_Procedure'][i])\n",
    "    elif(x_train['Procedure'][i] == 'C'):\n",
    "        x_c.append([x_train['Temperature'][i],x_train['EventTarget'][i]])\n",
    "        y_c.append(x_train['n_Procedure'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xamod = []\n",
    "xbmod = []\n",
    "xcmod = []\n",
    "tdiff = []\n",
    "for i in range(len(x_train)):\n",
    "    if(x_train['Procedure'][i] == 'A'):\n",
    "        if(i == 0):\n",
    "            xamod.append([x_train['Temperature'][i],x_train['EventTarget'][i],x_train['Temperature'][i]-24])\n",
    "            tdiff.append(x_train['Temperature'][i]-24)\n",
    "        else:\n",
    "            xamod.append([x_train['Temperature'][i],x_train['EventTarget'][i],x_train['Temperature'][i]-x_train['Temperature'][i-1]])\n",
    "            tdiff.append(x_train['Temperature'][i]-x_train['Temperature'][i]-x_train['Temperature'][i-1])\n",
    "    elif(x_train['Procedure'][i] == 'B'):\n",
    "        if(i == 0):\n",
    "            xbmod.append([x_train['Temperature'][i],x_train['EventTarget'][i],x_train['Temperature'][i]-24])\n",
    "            tdiff.append(x_train['Temperature'][i]-24)\n",
    "        else:\n",
    "            xbmod.append([x_train['Temperature'][i],x_train['EventTarget'][i],x_train['Temperature'][i]-x_train['Temperature'][i-1]])\n",
    "            tdiff.append(x_train['Temperature'][i]-x_train['Temperature'][i]-x_train['Temperature'][i-1])\n",
    "    elif(x_train['Procedure'][i] == 'C'):\n",
    "        if(i == 0):\n",
    "            xcmod.append([x_train['Temperature'][i],x_train['EventTarget'][i],x_train['Temperature'][i]-24])\n",
    "            tdiff.append(x_train['Temperature'][i]-24)\n",
    "        else:\n",
    "            xcmod.append([x_train['Temperature'][i],x_train['EventTarget'][i],x_train['Temperature'][i]-x_train['Temperature'][i-1]])   \n",
    "            tdiff.append(x_train['Temperature'][i]-x_train['Temperature'][i]-x_train['Temperature'][i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(326, 3)\n",
      "(326, 1, 3)\n",
      "(176, 1, 3)\n",
      "(176, 1, 3)\n",
      "(176, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train_A=np.array(xamod)\n",
    "x_train_B=np.array(xbmod)\n",
    "x_train_C=np.array(xcmod)\n",
    "print(x_train_B.shape)\n",
    "x_train_A = np.reshape(x_train_A, (x_train_A.shape[0], 1, x_train_A.shape[1]))\n",
    "x_train_B = np.reshape(x_train_B, (x_train_B.shape[0], 1, x_train_B.shape[1]))\n",
    "x_train_C = np.reshape(x_train_C, (x_train_C.shape[0], 1, x_train_C.shape[1]))\n",
    "\n",
    "print(np.shape(x_train_A))\n",
    "\n",
    "k = 150\n",
    "x_A,y_A = x_train_A[:-k],y_train_A[:-k]\n",
    "x_t_A,y_t_A = x_train_A[-k:],y_train_A[-k:]\n",
    "print(x_A.shape)\n",
    "\n",
    "\n",
    "x_B,y_B = x_train_B[:-k],y_train_B[:-k]\n",
    "x_t_B,y_t_B = x_train_B[-k:],y_train_B[-k:]\n",
    "print(x_B.shape)\n",
    "\n",
    "\n",
    "x_C,y_C = x_train_C[:-k],y_train_C[:-k]\n",
    "x_t_C,y_t_C = x_train_C[-k:],y_train_C[-k:]\n",
    "print(x_C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu = scaler.mu\n",
    "\n",
    "# std = np.sqrt(scaler.var_)\n",
    "# mu = scaler.mean_\n",
    "# std,mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM,Bidirectional\n",
    "def train_pred_eval_model(x_train_scaled, \\\n",
    "                          y_train_scaled, \\\n",
    "                          x_test_scaled, \\\n",
    "                          y_test, \\\n",
    "                          lstm_units=5, \\\n",
    "                          dropout_prob=0.5, \\\n",
    "                          optimizer='nadam', \\\n",
    "                          epochs=100, \\\n",
    "                          batch_size=10):\n",
    "    '''\n",
    "    Train model, do prediction, scale back to original range and do \n",
    "    evaluation\n",
    "    Use LSTM here.\n",
    "    Returns rmse, mape and predicted values\n",
    "    Inputs\n",
    "        x_train_scaled  : e.g. x_train_scaled.shape=(451, 9, 1). \n",
    "                          Here we are using the past 9 values to  \n",
    "                          predict the next value\n",
    "        y_train_scaled  : e.g. y_train_scaled.shape=(451, 1)\n",
    "        x_test_scaled   : use this to do predictions \n",
    "        y_test          : actual value of the predictions\n",
    "        mu_test_list    : list of the means. Same length as \n",
    "                          x_test_scaled and y_test\n",
    "        std_test_list   : list of the std devs. Same length as \n",
    "                          x_test_scaled and y_test\n",
    "        lstm_units      : dimensionality of the output space\n",
    "        dropout_prob    : fraction of the units to drop for the \n",
    "                          linear transformation of the inputs\n",
    "        optimizer       : optimizer for model.compile()\n",
    "        epochs          : epochs for model.fit()\n",
    "        batch_size      : batch size for model.fit()\n",
    "    Outputs\n",
    "        rmse            : root mean square error\n",
    "        mape            : mean absolute percentage error\n",
    "        est             : predictions\n",
    "    '''\n",
    "    # Create the LSTM network\n",
    "    model = Sequential()\n",
    "#     print(x_train_scaled.shape,y_train_scaled.shape,(x_train_scaled.shape[1],1))\n",
    "    model.add((LSTM(units=lstm_units,\n",
    "                   return_sequences=True, \n",
    "                   input_shape=(1,x_train_scaled.shape[2]))))\n",
    "    # Add dropput with a probability of 0.5\n",
    "    model.add(Dropout(dropout_prob)) \n",
    "    model.add(Bidirectional(LSTM(units=lstm_units)))\n",
    "    # Add dropput with a probability of 0.5\n",
    "    model.add(Dropout(dropout_prob)) \n",
    "    model.add(Dense(1))\n",
    "    # Compile and fit the LSTM network\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    model.fit(x_train_scaled, y_train_scaled, epochs=epochs,   \n",
    "              batch_size=batch_size, verbose=1)\n",
    "    \n",
    "    # Do prediction\n",
    "    est = model.predict(x_test_scaled)\n",
    "#     est = (est_scaled * np.array(std_test_list).reshape(-1,1)) +  np.array(mu_test_list).reshape(-1,1)\n",
    "    \n",
    "    # Calculate RMSE and MAPE\n",
    "    rmse = math.sqrt(mean_squared_error(y_test, est))\n",
    "    print(rmse)\n",
    "    print(np.exp(-rmse))\n",
    "    return rmse, est,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "176/176 [==============================] - 2s 9ms/step - loss: 35.8440\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 0s 453us/step - loss: 34.5529\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 0s 471us/step - loss: 32.6533\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 0s 448us/step - loss: 30.8585\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 0s 431us/step - loss: 27.5868\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 0s 326us/step - loss: 23.5765\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 0s 312us/step - loss: 20.7552\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 0s 334us/step - loss: 18.6693\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 0s 382us/step - loss: 16.5738\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 0s 402us/step - loss: 14.4686\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 0s 383us/step - loss: 14.0899\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 0s 439us/step - loss: 12.9610\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 0s 355us/step - loss: 12.3715\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 0s 381us/step - loss: 10.5989\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 0s 346us/step - loss: 10.1400\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 0s 356us/step - loss: 10.2910\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 0s 509us/step - loss: 9.4438\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 0s 490us/step - loss: 10.8049\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 0s 487us/step - loss: 10.4521\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 0s 396us/step - loss: 9.1562\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 0s 308us/step - loss: 8.4726\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 0s 309us/step - loss: 9.1066\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 0s 297us/step - loss: 7.8900\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 0s 319us/step - loss: 6.9179\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 0s 307us/step - loss: 8.2179\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 0s 351us/step - loss: 8.7193\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 0s 447us/step - loss: 9.1651\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 0s 410us/step - loss: 9.8674\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 0s 449us/step - loss: 8.5366\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 0s 442us/step - loss: 7.3192\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 0s 394us/step - loss: 8.2919\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 0s 324us/step - loss: 8.5290\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 0s 320us/step - loss: 9.2618\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 0s 337us/step - loss: 7.8558\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 0s 313us/step - loss: 8.3907\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 0s 341us/step - loss: 8.1733\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 0s 429us/step - loss: 8.3471\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 0s 463us/step - loss: 8.7884\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 0s 460us/step - loss: 8.0269\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 0s 471us/step - loss: 8.4750\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 0s 468us/step - loss: 7.6955\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 0s 382us/step - loss: 8.9236\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 0s 311us/step - loss: 7.8131\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 0s 333us/step - loss: 7.9544\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 0s 316us/step - loss: 7.3169\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 0s 321us/step - loss: 7.8193\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 0s 325us/step - loss: 8.0059\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 0s 339us/step - loss: 6.2503\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 0s 310us/step - loss: 7.5231\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 0s 345us/step - loss: 7.4852\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 0s 307us/step - loss: 8.4507\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 0s 310us/step - loss: 7.5933\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 0s 299us/step - loss: 7.6860\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 0s 298us/step - loss: 8.6486\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 0s 311us/step - loss: 8.8058\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 0s 294us/step - loss: 6.1449\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 0s 306us/step - loss: 8.3535\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 0s 312us/step - loss: 7.7847\n",
      "Epoch 59/100\n",
      "176/176 [==============================] - 0s 301us/step - loss: 7.0840\n",
      "Epoch 60/100\n",
      "176/176 [==============================] - 0s 309us/step - loss: 8.0504\n",
      "Epoch 61/100\n",
      "176/176 [==============================] - 0s 305us/step - loss: 7.3748\n",
      "Epoch 62/100\n",
      "176/176 [==============================] - 0s 313us/step - loss: 7.2369\n",
      "Epoch 63/100\n",
      "176/176 [==============================] - 0s 382us/step - loss: 6.7839\n",
      "Epoch 64/100\n",
      "176/176 [==============================] - 0s 373us/step - loss: 7.8379\n",
      "Epoch 65/100\n",
      "176/176 [==============================] - 0s 387us/step - loss: 7.3069\n",
      "Epoch 66/100\n",
      "176/176 [==============================] - 0s 374us/step - loss: 8.0140\n",
      "Epoch 67/100\n",
      "176/176 [==============================] - 0s 320us/step - loss: 8.1923\n",
      "Epoch 68/100\n",
      "176/176 [==============================] - 0s 388us/step - loss: 6.4257\n",
      "Epoch 69/100\n",
      "176/176 [==============================] - 0s 343us/step - loss: 6.7008\n",
      "Epoch 70/100\n",
      "176/176 [==============================] - 0s 357us/step - loss: 7.4003\n",
      "Epoch 71/100\n",
      "176/176 [==============================] - 0s 331us/step - loss: 7.9513\n",
      "Epoch 72/100\n",
      "176/176 [==============================] - 0s 407us/step - loss: 8.0299\n",
      "Epoch 73/100\n",
      "176/176 [==============================] - 0s 352us/step - loss: 7.2623\n",
      "Epoch 74/100\n",
      "176/176 [==============================] - 0s 299us/step - loss: 7.0675\n",
      "Epoch 75/100\n",
      "176/176 [==============================] - 0s 304us/step - loss: 7.7997\n",
      "Epoch 76/100\n",
      "176/176 [==============================] - 0s 303us/step - loss: 6.1592\n",
      "Epoch 77/100\n",
      "176/176 [==============================] - 0s 306us/step - loss: 6.5431\n",
      "Epoch 78/100\n",
      "176/176 [==============================] - 0s 305us/step - loss: 6.3246\n",
      "Epoch 79/100\n",
      "176/176 [==============================] - 0s 366us/step - loss: 7.9124\n",
      "Epoch 80/100\n",
      "176/176 [==============================] - 0s 321us/step - loss: 6.2660\n",
      "Epoch 81/100\n",
      "176/176 [==============================] - 0s 472us/step - loss: 6.8751\n",
      "Epoch 82/100\n",
      "176/176 [==============================] - 0s 485us/step - loss: 7.1845\n",
      "Epoch 83/100\n",
      "176/176 [==============================] - 0s 620us/step - loss: 7.4683\n",
      "Epoch 84/100\n",
      "176/176 [==============================] - 0s 457us/step - loss: 6.6128\n",
      "Epoch 85/100\n",
      "176/176 [==============================] - 0s 425us/step - loss: 7.4625\n",
      "Epoch 86/100\n",
      "176/176 [==============================] - 0s 302us/step - loss: 6.8426\n",
      "Epoch 87/100\n",
      "176/176 [==============================] - 0s 257us/step - loss: 6.6685\n",
      "Epoch 88/100\n",
      "176/176 [==============================] - 0s 258us/step - loss: 7.3306\n",
      "Epoch 89/100\n",
      "176/176 [==============================] - 0s 262us/step - loss: 6.3977\n",
      "Epoch 90/100\n",
      "176/176 [==============================] - 0s 265us/step - loss: 7.2742\n",
      "Epoch 91/100\n",
      "176/176 [==============================] - 0s 263us/step - loss: 8.1313\n",
      "Epoch 92/100\n",
      "176/176 [==============================] - 0s 262us/step - loss: 7.4376\n",
      "Epoch 93/100\n",
      "176/176 [==============================] - 0s 266us/step - loss: 7.3302\n",
      "Epoch 94/100\n",
      "176/176 [==============================] - 0s 275us/step - loss: 7.0897\n",
      "Epoch 95/100\n",
      "176/176 [==============================] - 0s 267us/step - loss: 7.2994\n",
      "Epoch 96/100\n",
      "176/176 [==============================] - 0s 278us/step - loss: 7.3556\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 302us/step - loss: 6.6924\n",
      "Epoch 98/100\n",
      "176/176 [==============================] - 0s 378us/step - loss: 6.7437\n",
      "Epoch 99/100\n",
      "176/176 [==============================] - 0s 389us/step - loss: 6.8988\n",
      "Epoch 100/100\n",
      "176/176 [==============================] - 0s 370us/step - loss: 6.2039\n",
      "2.157029590424529\n",
      "0.11566819316199409\n"
     ]
    }
   ],
   "source": [
    "val_A=train_pred_eval_model(x_A, \\\n",
    "                          y_A, \\\n",
    "                          x_t_A, \\\n",
    "                          y_t_A, \\\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_A = val_A[1]\n",
    "# pred1_A = np.round(pred_A)\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = val_A[2]\n",
    "y_pred = model.predict(x_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.233453072080482\n",
      "0.10715776704732244\n"
     ]
    }
   ],
   "source": [
    "#y_pred = np.round(y_pred)\n",
    "r = math.sqrt(mean_squared_error(y_pred,y_A))\n",
    "print(r)\n",
    "print(np.exp(-r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.403482 ]\n",
      " [5.386826 ]\n",
      " [5.406361 ]\n",
      " [5.4065685]\n",
      " [5.406602 ]\n",
      " [5.406377 ]\n",
      " [5.4049406]\n",
      " [5.405532 ]\n",
      " [5.4069324]\n",
      " [5.406686 ]\n",
      " [5.40237  ]\n",
      " [5.4023743]\n",
      " [5.405204 ]\n",
      " [5.4042187]\n",
      " [5.390283 ]\n",
      " [5.4064684]\n",
      " [5.4067664]\n",
      " [5.404384 ]\n",
      " [5.3951573]\n",
      " [5.404592 ]\n",
      " [5.4039187]\n",
      " [5.4059963]\n",
      " [5.3932066]\n",
      " [5.407055 ]\n",
      " [5.4068623]\n",
      " [5.4057884]\n",
      " [5.399556 ]\n",
      " [5.4068623]\n",
      " [5.406665 ]\n",
      " [5.406232 ]\n",
      " [5.4040155]\n",
      " [5.403723 ]\n",
      " [5.406743 ]\n",
      " [5.405417 ]\n",
      " [5.403723 ]\n",
      " [5.406753 ]\n",
      " [5.406655 ]\n",
      " [5.403828 ]\n",
      " [5.4052677]\n",
      " [5.4049196]\n",
      " [5.4060664]\n",
      " [5.40621  ]\n",
      " [5.404167 ]\n",
      " [5.40616  ]\n",
      " [5.4051023]\n",
      " [5.4058213]\n",
      " [5.405033 ]\n",
      " [5.40664  ]\n",
      " [5.4063215]\n",
      " [5.39818  ]\n",
      " [5.4070306]\n",
      " [5.407082 ]\n",
      " [5.404546 ]\n",
      " [5.4047527]\n",
      " [5.404384 ]\n",
      " [5.402138 ]\n",
      " [5.406743 ]\n",
      " [5.40649  ]\n",
      " [5.4069843]\n",
      " [5.406831 ]\n",
      " [5.406712 ]\n",
      " [5.4066844]\n",
      " [5.406982 ]\n",
      " [5.407036 ]\n",
      " [5.4068637]\n",
      " [5.4061804]\n",
      " [5.404898 ]\n",
      " [5.406949 ]\n",
      " [5.4068913]\n",
      " [5.4060874]\n",
      " [5.406449 ]\n",
      " [5.4061604]\n",
      " [5.3882213]\n",
      " [5.3866687]\n",
      " [5.4020514]\n",
      " [5.4041233]\n",
      " [5.4064155]\n",
      " [5.4063272]\n",
      " [5.406482 ]\n",
      " [5.406768 ]\n",
      " [5.407049 ]\n",
      " [5.407058 ]\n",
      " [5.407002 ]\n",
      " [5.4070115]\n",
      " [5.4069586]\n",
      " [5.4068885]\n",
      " [5.4068236]\n",
      " [5.3968787]\n",
      " [5.4055753]\n",
      " [5.399664 ]\n",
      " [5.406712 ]\n",
      " [5.4066844]\n",
      " [5.4070115]\n",
      " [5.399852 ]\n",
      " [5.405522 ]\n",
      " [5.400204 ]\n",
      " [5.406183 ]\n",
      " [5.4058213]\n",
      " [5.4064536]\n",
      " [5.406753 ]\n",
      " [5.406645 ]\n",
      " [5.406328 ]\n",
      " [5.405001 ]\n",
      " [5.4013796]\n",
      " [5.405559 ]\n",
      " [5.4065175]\n",
      " [5.406621 ]\n",
      " [5.406743 ]\n",
      " [5.406753 ]\n",
      " [5.4064503]\n",
      " [5.405204 ]\n",
      " [5.40057  ]\n",
      " [5.406461 ]\n",
      " [5.406163 ]\n",
      " [5.4061146]\n",
      " [5.4061856]\n",
      " [5.403164 ]\n",
      " [5.4029827]\n",
      " [5.4062753]\n",
      " [5.4059963]\n",
      " [5.40511  ]\n",
      " [5.404468 ]\n",
      " [5.4051843]\n",
      " [5.4046783]\n",
      " [5.401954 ]\n",
      " [5.4049153]\n",
      " [5.4047837]\n",
      " [5.401062 ]\n",
      " [5.404479 ]\n",
      " [5.4046783]\n",
      " [5.4032774]\n",
      " [5.404737 ]\n",
      " [5.40168  ]\n",
      " [5.4059286]\n",
      " [5.4055753]\n",
      " [5.4048796]\n",
      " [5.404346 ]\n",
      " [5.400369 ]\n",
      " [5.4028416]\n",
      " [5.404069 ]\n",
      " [5.404818 ]\n",
      " [5.405585 ]\n",
      " [5.4054685]\n",
      " [5.404855 ]\n",
      " [5.4033175]\n",
      " [5.3988023]\n",
      " [5.401535 ]\n",
      " [5.4003844]\n",
      " [5.4054685]\n",
      " [5.404818 ]]\n",
      "528    10\n",
      "531     4\n",
      "534     9\n",
      "537     3\n",
      "540     7\n",
      "       ..\n",
      "963     5\n",
      "966     4\n",
      "969     7\n",
      "972     4\n",
      "975     5\n",
      "Name: n_Procedure, Length: 150, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pred_A)\n",
    "print(y_t_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.157029590424529\n",
      "0.11566819316199409\n"
     ]
    }
   ],
   "source": [
    "z_A=y_t_A\n",
    "r = math.sqrt(mean_squared_error(z_A,pred_A))\n",
    "print(r)\n",
    "print(np.exp(-r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_B=train_pred_eval_model(x_B, \\\n",
    "                          y_B, \\\n",
    "                          x_t_B, \\\n",
    "                          y_t_B, \\\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_B = val_B[1]\n",
    "# pred1_B = np.round(pred_B)\n",
    "# pred1_B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_B=y_t_B\n",
    "r = math.sqrt(mean_squared_error(z_B,pred_B))\n",
    "r\n",
    "print(np.exp(-r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_C=train_pred_eval_model(x_C, \\\n",
    "                          y_C, \\\n",
    "                          x_t_C, \\\n",
    "                          y_t_C, \\\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_C = val_C[1]\n",
    "pred1_C = np.round(pred_C)\n",
    "pred1_C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_C=y_t_C\n",
    "r = math.sqrt(mean_squared_error(z_C,pred1_C))\n",
    "print(r)\n",
    "print(np.exp(-r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A=val_A[2]\n",
    "model_B=val_B[2]\n",
    "model_C=val_C[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(test)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
